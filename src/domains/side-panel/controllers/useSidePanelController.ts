import { useEffect, useCallback, useRef } from 'react';
import { useSidePanelStore } from './store';
import { useSpeechRecognition } from '../features/voice-recognition/hook/useSpeechRecognition';

export const useSidePanelController = () => {
  const {
    analysisResult,
    activeTabId,
    setAnalysisResult,
    // âœ¨ 1. ìƒˆë¡œ ë§Œë“  ìŠ¤í† ì–´ ì•¡ì…˜ ê°€ì ¸ì˜¤ê¸°
    addAnalysisItems,
    setActiveTabId,
    getFilteredItems,
    filter,
    searchTerm,
    setFilter,
    setSearchTerm,
  } = useSidePanelStore();

  const analysisResultRef = useRef(analysisResult);
  const activeTabIdRef = useRef(activeTabId);

  useEffect(() => {
    analysisResultRef.current = analysisResult;
  }, [analysisResult]);

  useEffect(() => {
    activeTabIdRef.current = activeTabId;
  }, [activeTabId]);


  useEffect(() => {
    chrome.tabs.query({ active: true, currentWindow: true }, (tabs) => {
      if (tabs[0]?.id) setActiveTabId(tabs[0].id);
    });
    
    const messageListener = (request: any) => {
      // ê¸°ì¡´ ì „ì²´ ì—…ë°ì´íŠ¸ ë¡œì§
      if (request.action === 'updatePanelData') {
        console.log('ðŸ”„ Side Panel: Received full update with', request.data.items.length, 'items');
        setAnalysisResult(request.data);
      } 
      
      // âœ¨ 2. ìƒˆë¡œìš´ ì•„ì´í…œ ì¶”ê°€ ë¡œì§
      else if (request.action === 'addNewItems') {
        console.log('ðŸ”„ Side Panel: Received', request.data.length, 'new items to add.');
        addAnalysisItems(request.data);
      }
    };
    
    chrome.runtime.onMessage.addListener(messageListener);
    return () => chrome.runtime.onMessage.removeListener(messageListener);
    
    // âœ¨ 3. ì˜ì¡´ì„± ë°°ì—´ì— addAnalysisItems ì¶”ê°€
  }, [setActiveTabId, setAnalysisResult, addAnalysisItems]);

  const handleItemClick = (ownerId: number) => {
    if (activeTabId) {
      chrome.runtime.sendMessage({ action: 'highlightElement', tabId: activeTabId, ownerId: ownerId });
    }
  };

  const handleVoiceCommand = useCallback((command: string) => {
    const currentTabId = activeTabIdRef.current;
    // âœ¨ ì¤‘ìš”: content_scriptì™€ ë™ê¸°í™”ëœ ìµœì‹  analysisResultë¥¼ refì—ì„œ ì§ì ‘ ì°¸ì¡°í•©ë‹ˆë‹¤.
    const currentAnalysisResult = analysisResultRef.current;
    
    console.log('ðŸŽ¤ Voice command received:', command);
    
    if (!currentAnalysisResult || !currentTabId) {
      console.warn('âŒ No analysis result or tab ID available for voice command');
      return;
    }
    
    chrome.runtime.sendMessage({
      action: 'executeVoiceCommand',
      command: command,
      tabId: currentTabId
    });
  }, []); // ì˜ì¡´ì„± ë°°ì—´ì€ ë¹„ì›Œë‘¡ë‹ˆë‹¤.

  const { transcribedText, isListening, toggleListening, error } = useSpeechRecognition(handleVoiceCommand);

  const exportData = () => {
    if (!analysisResult) return;
    const dataStr = JSON.stringify(analysisResult, null, 2);
    const dataUri = 'data:application/json;charset=utf-8,' + encodeURIComponent(dataStr);
    const exportFileDefaultName = `crawl-${new Date().getTime()}.json`;
    const linkElement = document.createElement('a');
    linkElement.setAttribute('href', dataUri);
    linkElement.setAttribute('download', exportFileDefaultName);
    linkElement.click();
  };

  return {
    analysisResult,
    filter,
    onFilterChange: setFilter,
    searchTerm,
    onSearchTermChange: setSearchTerm,
    filteredItems: getFilteredItems(),
    onItemClick: handleItemClick,
    isListening,
    transcribedText,
    onToggleListening: toggleListening,
    onExportData: exportData,
    recognitionError: error,
  };
};
