// AI ì¶”ë¡  ì»¨íŠ¸ë¡¤ëŸ¬ - Gemma 3 1B ëª¨ë¸ (API í† í° ë‹¤ìš´ë¡œë“œ ë°©ì‹)

import { LlmInference, FilesetResolver } from '@mediapipe/tasks-genai';
import { openDB } from 'idb';
import { VoiceIntent, AIAnalysisResult, AIModelConfig, AIModelStatus } from '../types/ai-types';

// IndexedDB ì„¤ì •
const DB_NAME = 'ai-model-cache';
const MODEL_STORE_NAME = 'models';
const MODEL_KEY = 'gemma3-1b-it-int4';
const DB_VERSION = 2;


export class AIController {
  private llm: LlmInference | null = null;
  private modelStatus: AIModelStatus = {
    state: 1 // 1: ìºì‹œì—†ìŒ/ë¡œë”©ì•ˆë¨
  };

  private readonly fullConfig: AIModelConfig;

  constructor(config: AIModelConfig = {}) {
    this.fullConfig = {
      // Hugging Faceì˜ Gated Model ê²½ë¡œ
      modelPath: "https://huggingface.co/litert-community/Gemma3-1B-IT/resolve/main/gemma3-1b-it-int4.task?download=true",
      maxTokens: 2048,
      // âœ¨ [ìˆ˜ì •] ì˜¨ë„ ê°’ì„ ë‚®ì¶° ë¶„ë¥˜ ì •í™•ë„ í–¥ìƒ
      temperature: 0.2,
      topK: 40,
      randomSeed: 42,
      ...config
    };
    console.log('ğŸ¤– [ai-controller] Config initialized for API token download.');
  }

  /**
   * MediaPipe LLM ì´ˆê¸°í™” (ë¡œì»¬ ìºì‹œ ìš°ì„ )
   */
  async initialize(): Promise<boolean> {
    if (this.modelStatus.state === 3) return true; // ì´ë¯¸ ë¡œë“œë¨
    if (this.modelStatus.state === 2) return false; // ë¡œë”© ì¤‘

    try {
      this.modelStatus.state = 2; // ë¡œë”© ì¤‘
      const startTime = Date.now();
      console.log('ğŸš€ [ai-controller] Initializing AI model from local cache...');

      const db = await openDB(DB_NAME, DB_VERSION);
      const modelTaskFile = await db.get(MODEL_STORE_NAME, MODEL_KEY) as ArrayBuffer;

      if (!modelTaskFile || typeof modelTaskFile.byteLength === 'undefined') {
        console.error('âŒ [ai-controller] No model task file found in cache. Please download the model.');
        this.modelStatus = { state: 1, error: 'Model not found in cache.' };
        return false;
      }
      console.log(`âœ… [ai-controller] Found .task file in IndexedDB. Size: ${modelTaskFile.byteLength} bytes.`);

      const modelData = new Uint8Array(modelTaskFile);
      console.log(`- Loaded .task bundle directly. Size: ${modelData.byteLength} bytes.`);

      const wasmPath = chrome.runtime.getURL("wasm_files/");
      const genaiFileset = await FilesetResolver.forGenAiTasks(wasmPath);
      
      this.llm = await LlmInference.createFromOptions(genaiFileset, {
        baseOptions: { modelAssetBuffer: modelData },
        maxTokens: this.fullConfig.maxTokens!,
        temperature: this.fullConfig.temperature!,
        topK: this.fullConfig.topK!,
        randomSeed: this.fullConfig.randomSeed!
      });

      const loadTime = Date.now() - startTime;
      this.modelStatus = {
        state: 3, // ë¡œë”© ì™„ë£Œ
        modelSize: modelData.byteLength,
        loadTime: loadTime
      };

      console.log(`âœ… [ai-controller] SUCCESS: Model loaded from .task bundle in ${loadTime}ms`);
      return true;

    } catch (error: any) {
      this.modelStatus = { state: 1, error: error.message };
      console.error('âŒ [ai-controller] FAILED to initialize from cache:', error);
      return false;
    }
  }

  /**
   * API í† í°ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ìºì‹±
   */
  async downloadAndCacheModel(token: string): Promise<boolean> {
    console.log('ğŸ“¥ [ai-controller] Downloading model from Hugging Face with API token...');
    this.modelStatus = { state: 2 }; // ë¡œë”© ì¤‘
    try {
      const response = await fetch(this.fullConfig.modelPath!, {
        headers: {
          Authorization: `Bearer ${token}`,
        },
      });

      if (!response.ok) {
        throw new Error(`Failed to download model: ${response.status} ${response.statusText}`);
      }
      const modelBuffer = await response.arrayBuffer();
      console.log(`âœ… [ai-controller] Model downloaded successfully (${(modelBuffer.byteLength / 1024 / 1024).toFixed(2)}MB)`);
  
      const db = await openDB(DB_NAME, DB_VERSION, {
        upgrade(db) {
          if (!db.objectStoreNames.contains(MODEL_STORE_NAME)) {
            db.createObjectStore(MODEL_STORE_NAME);
            console.log('âœ… [idb] Object store created during download.');
          }
        },
      });
      await db.put(MODEL_STORE_NAME, modelBuffer, MODEL_KEY);
      console.log('ğŸ’¾ [ai-controller] Model saved to IndexedDB.');
      
      return this.initialize();
  
    } catch (error: any) {
      console.error('âŒ [ai-controller] Failed to download or cache model:', error);
      this.modelStatus = { state: 1, error: error.message };
      return false;
    }
  }
  
  /**
   * ìºì‹œëœ ëª¨ë¸ ì‚­ì œ
   */
  async deleteCachedModel(): Promise<void> {
    const db = await openDB(DB_NAME, DB_VERSION);
    await db.delete(MODEL_STORE_NAME, MODEL_KEY);
    if (this.llm) this.llm = null;
    this.modelStatus = { state: 1 }; // ìºì‹œ ì—†ìŒ
    console.log('âœ… [ai-controller] Cached model deleted.');
  }

  /**
   * IndexedDBì—ì„œ ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ë§Œ ì²´í¬ (ë¡œë”©í•˜ì§€ ì•ŠìŒ)
   */
  async checkModelExists(): Promise<boolean> {
    try {
      const db = await openDB(DB_NAME, DB_VERSION);
      const modelTaskFile = await db.get(MODEL_STORE_NAME, MODEL_KEY) as ArrayBuffer;
      const exists = modelTaskFile && typeof modelTaskFile.byteLength !== 'undefined' && modelTaskFile.byteLength > 0;
      console.log(`ğŸ” [ai-controller] Model exists in IndexedDB: ${exists}`);
      return exists;
    } catch (error) {
      console.error('âŒ [ai-controller] Failed to check model existence:', error);
      return false;
    }
  }

  /**
   * ëª¨ë¸ ìƒíƒœ í™•ì¸ (IndexedDB ì¡´ì¬ ì—¬ë¶€ ë°˜ì˜)
   */
  async getModelStatus(): Promise<AIModelStatus> {
    if (this.modelStatus.state === 1) {
      const modelExists = await this.checkModelExists();
      if (modelExists) {
        this.modelStatus = {
          ...this.modelStatus,
          state: 4 
        };
        console.log('ğŸ“¦ [ai-controller] Model found in cache but not loaded in memory');
      }
    }
    return { ...this.modelStatus };
  }

  /**
   * ìŒì„± ëª…ë ¹ ì˜ë„ ë¶„ì„ (ì‹¤ì œ AI ì¶”ë¡ )
   */
  async analyzeIntent(voiceInput: string): Promise<AIAnalysisResult> {
    console.log('ğŸ¯ [ai-controller] Analyzing voice intent with Gemma 3 1B:', voiceInput);

    if (this.modelStatus.state !== 3 || !this.llm) {
      console.log('âš ï¸ [ai-controller] Model not loaded, using fallback analysis');
      throw new Error('AI model is not initialized.');
    }

    try {
      const prompt = this.buildAnalysisPrompt(voiceInput);
      const response = await this.llm.generateResponse(prompt);
      return this.parseAIResponse(response, voiceInput);

    } catch (error: any) {
      console.error('âŒ [ai-controller] AI analysis failed:', error);
      throw error;
    }
  }

  /**
   * âœ¨ [ìˆ˜ì •] ìš°ì„ ìˆœìœ„ ê·œì¹™ì„ ëª…ì‹œí•˜ì—¬ ë¶„ë¥˜ ì •í™•ë„ í–¥ìƒ
   */
private buildAnalysisPrompt(voiceInput: string): string {
  return `<start_of_turn>user
You are an expert Korean voice command classifier. 
Classify into ONE category: ["price_comparison", "purchase_flow", "simple_find", "navigation", "product_search"]

Respond with JSON:
{"action": "category", "product": "...", "target": "...", "confidence": 0.95, "reasoning": "explanation"}

Rules (STRICT ORDER):
1. **price_comparison**: ê°€ê²©/í• ì¸ ê´€ë ¨ ("ìµœì €ê°€", "í• ì¸ê°€", "ì–¼ë§ˆ", "ì‹¼ ê³³")
2. **purchase_flow**: êµ¬ë§¤/ì£¼ë¬¸ ("ì¥ë°”êµ¬ë‹ˆ", "ê²°ì œ", "ì£¼ë¬¸", "êµ¬ë§¤", "ì¹´íŠ¸")  
3. **simple_find**: UI ì¡°ì‘ ("ë²„íŠ¼", "ë§í¬", "ë©”ë‰´", "ì•„ì´ì½˜", "ê²€ìƒ‰ì°½" + "í´ë¦­/ëˆŒëŸ¬/ì°¾ì•„")
4. **navigation**: í˜ì´ì§€ ì´ë™ ("ë’¤ë¡œ", "ì•ìœ¼ë¡œ", "í™ˆìœ¼ë¡œ", "ì´ì „ í˜ì´ì§€")
5. **product_search**: ìƒí’ˆ ê²€ìƒ‰ (ì œí’ˆëª… + "ì°¾ì•„/ê²€ìƒ‰/ë³´ì—¬")

Examples:
- "ê²€ìƒ‰ì°½ ì°¾ì•„ì¤˜" â†’ {"action": "simple_find", "target": "ê²€ìƒ‰ì°½", "confidence": 0.90}
- "ë©”ë‰´ ë²„íŠ¼ ëˆŒëŸ¬ì¤˜" â†’ {"action": "simple_find", "target": "ë©”ë‰´ ë²„íŠ¼", "confidence": 0.88}
- "ì¹´íŠ¸ì— ì¶”ê°€í•´ì¤˜" â†’ {"action": "purchase_flow", "target": "ì¹´íŠ¸", "confidence": 0.92}
- "ì•„ì´í° ì°¾ì•„ì¤˜" â†’ {"action": "product_search", "product": "ì•„ì´í°", "confidence": 0.95}

Command: "${voiceInput}"
<end_of_turn>
<start_of_turn>model`;
}



  /**
   * âœ¨ [ìˆ˜ì •] ì•ˆì •ì ì¸ íŒŒì‹± ë¡œì§ ìœ ì§€
   */
private parseAIResponse(response: string, originalCommand: string): AIAnalysisResult {
  try {
    console.log('ğŸ” [ai-controller] Raw AI response:', response);
    
    const firstBrace = response.indexOf('{');
    const lastBrace = response.lastIndexOf('}');
    
    if (firstBrace === -1 || lastBrace === -1 || lastBrace < firstBrace) {
      console.warn('âš ï¸ [ai-controller] No valid JSON object found in response, using fallback.');
      const fallbackAction = this.guessActionFromText(originalCommand);
      const intent: VoiceIntent = {
        action: fallbackAction,
        confidence: 0.8,
        reasoning: 'Fallback analysis (No JSON found)'
      };
      return { intent, reasoning: 'Fallback analysis (No JSON found)' };
    }
    
    let jsonString = response.substring(firstBrace, lastBrace + 1);
    
    // âœ¨ JSON ì •ë¦¬ ë¡œì§ ì¶”ê°€
    jsonString = this.sanitizeJsonString(jsonString);
    
    const parsedResponse = JSON.parse(jsonString);
    
    const intent: VoiceIntent = {
      action: parsedResponse.action || 'unknown',
      product: parsedResponse.product,
      target: parsedResponse.target,
      detail: parsedResponse.detail,
      confidence: parsedResponse.confidence || 0.8,
      reasoning: parsedResponse.reasoning || 'AI analysis complete'
    };
    
    return {
      intent,
      reasoning: parsedResponse.reasoning || 'AI analysis complete',
    };
  } catch (error: any) {
    console.error('âŒ [ai-controller] Failed to parse AI response:', error);
    console.error('âŒ [ai-controller] Response was:', response);
    
    // âœ¨ fallback ì²˜ë¦¬ ì¶”ê°€
    const fallbackAction = this.guessActionFromText(originalCommand);
    const intent: VoiceIntent = {
      action: fallbackAction,
      confidence: 0.7,
      reasoning: 'Fallback analysis (JSON parsing failed)'
    };
    return { intent, reasoning: 'Fallback analysis (JSON parsing failed)' };
  }
}

// âœ¨ ì´ ë©”ì„œë“œë„ ì¶”ê°€
private sanitizeJsonString(jsonString: string): string {
  try {
    // reasoning ê°’ ë‚´ë¶€ì˜ ë”°ì˜´í‘œ ë¬¸ì œ í•´ê²°
    const reasoningMatch = jsonString.match(/"reasoning":\s*"([^"]*(?:"[^"]*"[^"]*)*[^"]*)"/);
    if (reasoningMatch) {
      const originalReasoning = reasoningMatch[1];
      // ë‚´ë¶€ ë”°ì˜´í‘œë¥¼ ì‘ì€ë”°ì˜´í‘œë¡œ ë³€ê²½
      const cleanReasoning = originalReasoning.replace(/"/g, "'");
      jsonString = jsonString.replace(reasoningMatch[0], `"reasoning": "${cleanReasoning}"`);
    }
    
    // ê¸°íƒ€ ì¼ë°˜ì ì¸ JSON ì˜¤ë¥˜ ìˆ˜ì •
    jsonString = jsonString.replace(/[\r\n\t]/g, ' '); // ê°œí–‰ë¬¸ì ì œê±°
    jsonString = jsonString.replace(/,\s*}/g, '}');    // ë§ˆì§€ë§‰ ì½¤ë§ˆ ì œê±°
    
    console.log('ğŸ”§ [ai-controller] Sanitized JSON:', jsonString);
    return jsonString;
  } catch (error) {
    console.warn('âš ï¸ [ai-controller] JSON sanitization failed:', error);
    return jsonString; // ì›ë³¸ ë°˜í™˜
  }
}

  private guessActionFromText(text: string): VoiceIntent['action'] {
    const lower = text.toLowerCase();
    console.log('ğŸ” [ai-controller] Fallback analysis for:', lower);
    
    if ((lower.includes('ì•„ì´í°') || lower.includes('ê°¤ëŸ­ì‹œ') || lower.includes('ë…¸íŠ¸ë¶')) && 
        (lower.includes('ì°¾ì•„') || lower.includes('ê²€ìƒ‰'))) {
      return 'product_search';
    }
    if (lower.includes('ìµœì €ê°€') || lower.includes('ê°€ê²©') || lower.includes('ë¹„êµ')) return 'price_comparison';
    if (lower.includes('ë²„íŠ¼') || lower.includes('í´ë¦­') || lower.includes('ëˆŒëŸ¬')) return 'simple_find';
    if (lower.includes('ì¥ë°”êµ¬ë‹ˆ') || lower.includes('êµ¬ë§¤') || lower.includes('ê²°ì œ')) return 'purchase_flow';
    if (lower.includes('ì´ì „') || lower.includes('ë’¤ë¡œ') || lower.includes('ì´ë™')) return 'navigation';
    if (lower.includes('ì°¾ì•„') || lower.includes('ê²€ìƒ‰')) return 'product_search';
    
    return 'unknown';
  }
}

let aiControllerInstance: AIController | null = null;

export function getAIController(): AIController {
  if (!aiControllerInstance) {
    aiControllerInstance = new AIController();
  }
  return aiControllerInstance;
}
