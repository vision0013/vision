// src/features/ai-inference/controllers/inference-engine.ts

import { LlmInference } from '@mediapipe/tasks-genai';
import { CrawledItem, Mode } from '../../../types';
import { AIAnalysisResult } from '../types/ai-types';
import { getPromptTemplate, AI_PROMPTS, getBaseExamples } from '../config/ai-prompts';
import { AIResponseParser } from '../process/ai-response-parser';
import type { AIController } from './ai-controller';

/**
 * AI ì¶”ë¡  ì‹¤í–‰ ë° í”„ë¡¬í”„íŠ¸ êµ¬ì„±ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
 */
export class InferenceEngine {
  private isAnalyzing = false;
  private analysisQueue: Array<{ 
    voiceInput: string;
    crawledItems: CrawledItem[];
    mode: Mode; // âœ¨ [ì‹ ê·œ] íì— mode ì¶”ê°€
    resolve: (result: AIAnalysisResult) => void;
    reject: (error: Error) => void;
  }> = [];

  private currentPromptName: keyof typeof AI_PROMPTS = 'AGENT_PLANNER';

  constructor(
    private llm: LlmInference | null,
    private aiController: AIController
  ) {}

  public setLlm(llm: LlmInference | null) {
    this.llm = llm;
  }

  // âœ¨ [ìˆ˜ì •] modeë¥¼ ì¸ìë¡œ ë°›ë„ë¡ ë³€ê²½
  async analyzeIntent(voiceInput: string, crawledItems: CrawledItem[], mode: Mode): Promise<AIAnalysisResult> {
    return new Promise((resolve, reject) => {
      this.analysisQueue.push({ voiceInput, crawledItems, mode, resolve, reject });
      this.processAnalysisQueue();
    });
  }

  async analyzeChat(userInput: string): Promise<string> {
    if (!this.aiController.isReadyForInference()) {
      throw new Error('AI model is not ready for inference');
    }

    try {
      const originalPrompt = this.currentPromptName;
      this.setPromptTemplate('CHAT_ASSISTANT');

      const prompt = await this.buildChatPrompt(userInput);
      const response = await this.llm!.generateResponse(prompt);
      const result = AIResponseParser.parseChatResponse(response);

      this.setPromptTemplate(originalPrompt);
      return result;
    } catch (error: any) {
      console.error('âŒ [inference-engine] Chat analysis failed:', error);
      throw error;
    }
  }

  private async buildChatPrompt(userInput: string): Promise<string> {
    const promptTemplate = getPromptTemplate('CHAT_ASSISTANT');
    return promptTemplate.template(userInput, [], [], 'chat');
  }

  private async processAnalysisQueue(): Promise<void> {
    if (!this.aiController.isReadyForInference() || this.isAnalyzing || this.analysisQueue.length === 0) {
      return;
    }

    this.isAnalyzing = true;
    // âœ¨ [ìˆ˜ì •] íì—ì„œ mode êº¼ë‚´ê¸°
    const { voiceInput, crawledItems, mode, resolve, reject } = this.analysisQueue.shift()!;

    try {
      // âœ¨ [ìˆ˜ì •] buildAnalysisPromptì— mode ì „ë‹¬
      const prompt = await this.buildAnalysisPrompt(voiceInput, crawledItems, mode);

      // ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
      const inferenceStartTime = performance.now();
      const response = await this.llm!.generateResponse(prompt);
      const inferenceEndTime = performance.now();
      const inferenceTime = inferenceEndTime - inferenceStartTime;

      console.log(`ğŸš€ [inference-engine] AI inference took ${inferenceTime.toFixed(2)}ms`);
      console.log(`ğŸ“Š [inference-engine] Mode: ${mode}, Input length: ${voiceInput.length}`);
      console.log(`ğŸ¤– [inference-engine] Current Model: ${this.aiController.getCurrentModelId()}`);

      const result = AIResponseParser.parseAIResponse(response, voiceInput, mode);
      resolve(result);
    } catch (error: any) {
      console.error('âŒ [inference-engine] AI analysis failed:', error);
      reject(error);
    } finally {
      this.isAnalyzing = false;
      this.processAnalysisQueue();
    }
  }

  // âœ¨ [ìˆ˜ì •] buildAnalysisPrompt ì‹œê·¸ë‹ˆì²˜ ë³€ê²½
  private async buildAnalysisPrompt(voiceInput: string, crawledItems: CrawledItem[], mode: Mode): Promise<string> {
    // ì±„íŒ… ëª¨ë“œì¼ ë•ŒëŠ” CHAT_ASSISTANT í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    const promptName = mode === 'chat' ? 'CHAT_ASSISTANT' : this.currentPromptName;
    const promptTemplate = getPromptTemplate(promptName);
    const baseExamples = getBaseExamples();
    // âœ¨ [ìˆ˜ì •] template í•¨ìˆ˜ì— mode ì „ë‹¬
    return promptTemplate.template(voiceInput, baseExamples, crawledItems, mode);
  }

  public setPromptTemplate(promptName: keyof typeof AI_PROMPTS): void {
    this.currentPromptName = promptName;
  }

  public getCurrentPrompt(): string {
    return AI_PROMPTS[this.currentPromptName].name;
  }

  public getAvailablePrompts(): Array<{ name: keyof typeof AI_PROMPTS, description: string }> {
    return Object.entries(AI_PROMPTS).map(([key, value]) => ({
      name: key as keyof typeof AI_PROMPTS,
      description: value.description
    }));
  }
}
