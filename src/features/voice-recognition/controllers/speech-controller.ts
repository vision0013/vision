import { useState, useEffect, useRef, useCallback } from 'react';
import { createSpeechEngine } from '../process/speech-engine';

export const useSpeechRecognition = (onCommand: (command: string) => void) => {
  const [isListening, setIsListening] = useState(false);
  const [transcribedText, setTranscribedText] = useState('');
  const [error, setError] = useState<string | null>(null);
  
  const speechEngine = useRef(createSpeechEngine());
  const isListeningRef = useRef(isListening);
  const onCommandRef = useRef(onCommand);
  
  // ê²°ê³¼ ë³‘í•©ì„ ìœ„í•œ ìƒíƒœ
  const commandBuffer = useRef('');
  const lastResultTime = useRef(0);
  const COMMAND_MERGE_DELAY = 2000; // 2ì´ˆë¡œ ì—°ì¥
  const mergeTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  useEffect(() => {
    isListeningRef.current = isListening;
  }, [isListening]);

  useEffect(() => {
    onCommandRef.current = onCommand;
  }, [onCommand]);

  useEffect(() => {
    if (!speechEngine.current.isSupported()) {
      console.error("âŒ SpeechRecognition APIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
      setError('not-supported');
    }
  }, []);

  const handleResult = useCallback((transcript: string, isFinal: boolean) => {
    const now = Date.now();
    
    if (isFinal) {
      const trimmedTranscript = transcript.trim();
      console.log("ğŸ¤ Final transcript:", trimmedTranscript);
      
      // ì´ì „ ê²°ê³¼ì™€ ì‹œê°„ ê°„ê²© í™•ì¸
      if (commandBuffer.current && (now - lastResultTime.current < COMMAND_MERGE_DELAY)) {
        // ë³‘í•©
        const mergedCommand = `${commandBuffer.current} ${trimmedTranscript}`.trim();
        console.log("ğŸ”— Merging commands:", commandBuffer.current, "+", trimmedTranscript, "=", mergedCommand);
        
        // ê¸°ì¡´ íƒ€ì´ë¨¸ ì·¨ì†Œ
        if (mergeTimeoutRef.current) {
          clearTimeout(mergeTimeoutRef.current);
          mergeTimeoutRef.current = null;
        }
        
        commandBuffer.current = '';
        onCommandRef.current(mergedCommand);
      } else {
        // ê¸°ì¡´ íƒ€ì´ë¨¸ ì·¨ì†Œ
        if (mergeTimeoutRef.current) {
          clearTimeout(mergeTimeoutRef.current);
        }
        
        // ìƒˆë¡œìš´ ëª…ë ¹ì–´ ì‹œì‘ - ë²„í¼ì— ì €ì¥í•˜ê³  ì ì‹œ ëŒ€ê¸°
        commandBuffer.current = trimmedTranscript;
        lastResultTime.current = now;
        
        // 2ì´ˆ í›„ ë²„í¼ê°€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ìˆìœ¼ë©´ ë‹¨ë… ëª…ë ¹ìœ¼ë¡œ ì²˜ë¦¬
        mergeTimeoutRef.current = setTimeout(() => {
          if (commandBuffer.current === trimmedTranscript) {
            console.log("ğŸ¤ Single command:", commandBuffer.current);
            onCommandRef.current(commandBuffer.current);
            commandBuffer.current = '';
          }
          mergeTimeoutRef.current = null;
        }, COMMAND_MERGE_DELAY);
      }
      
      setTranscribedText('');
    } else {
      setTranscribedText(transcript);
    }
  }, []);

  const handleError = useCallback((errorMessage: string) => {
    console.error("ğŸš¨ ìŒì„± ì¸ì‹ ì˜¤ë¥˜:", errorMessage);
    setError(errorMessage);
    if (errorMessage === 'not-allowed') {
      setIsListening(false);
    }
  }, []);

  const handleEnd = useCallback(() => {
    console.log("ğŸ¤ Recognition ended, restarting if still listening:", isListeningRef.current);
    if (isListeningRef.current) {
      const success = speechEngine.current.startListening(handleResult, handleError, handleEnd);
      if (!success) {
        setIsListening(false);
      }
    }
  }, [handleResult, handleError]);

  const toggleListening = useCallback(() => {
    const newIsListening = !isListening;
    setIsListening(newIsListening);

    if (newIsListening) {
      setError(null);
      setTranscribedText('');
      const success = speechEngine.current.startListening(handleResult, handleError, handleEnd);
      if (!success) {
        setIsListening(false);
      }
    } else {
      speechEngine.current.stopListening();
    }
  }, [isListening, handleResult, handleError, handleEnd]);

  return { 
    transcribedText, 
    isListening, 
    toggleListening, 
    error 
  };
};