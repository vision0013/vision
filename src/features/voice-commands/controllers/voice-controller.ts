import { CrawledItem } from "@/types";
import { VoiceCommandResult } from "../types/voice-types";
import { clickAction } from "../process/click-action";
import { findAction } from "../process/find-action";
import { scrollAction } from "../process/scroll-action";
import { inputAction } from "../process/input-action";
import { navigationAction } from "../process/navigation-action";
import { mapAIToVoiceActions, VoiceActionStep } from "../process/ai-action-mapper";
import { getAIController } from "../../ai-inference/controllers/ai-controller";

// âœ¨ [ê°œì„ ] í•¨ìˆ˜ì— ì „ë‹¬ë  íŒŒë¼ë¯¸í„°ë¥¼ ìœ„í•œ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
interface CommandPayload {
  detectedAction: string;
  targetText: string;
  direction: 'up' | 'down' | null;
  originalCommand: string;
  items: CrawledItem[];
}

/**
 * background.tsì—ì„œ ë¯¸ë¦¬ ë¶„ì„ëœ ëª…ë ¹ì–´ ì •ë³´ë¥¼ ë°›ì•„,
 * ì ì ˆí•œ ì•¡ì…˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ë¼ìš°í„° ì—­í• ì„ í•©ë‹ˆë‹¤.
 * @param payload ëª…ë ¹ì–´ ë¶„ì„ ê²°ê³¼ê°€ ë‹´ê¸´ ê°ì²´
 * @returns VoiceCommandResult ì•¡ì…˜ ì‹¤í–‰ ê²°ê³¼
 */
export function processVoiceCommand(payload: CommandPayload): VoiceCommandResult {
  // âœ¨ [ê°œì„ ] ê°ì²´ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ë°”ë¡œ êµ¬ì¡° ë¶„í•´ í• ë‹¹í•˜ì—¬ ì‚¬ìš©
  const { detectedAction, targetText, direction, originalCommand, items } = payload;

  console.log(`âœ… [CONTROLLER] Executing: ${detectedAction}, Target: "${targetText}", Direction: ${direction}`);

  if (!targetText && ['click', 'find'].includes(detectedAction)) {
    return { type: "not_found", message: "ëŒ€ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." };
  }

  switch (detectedAction) {
    case 'click':
      return clickAction(targetText, items, direction);

    case 'find':
      return findAction(targetText, items, direction);

    case 'scroll':
      return scrollAction(targetText, items, direction);

    case 'input':
      return inputAction(originalCommand, items);

    case 'navigation':
      return navigationAction(targetText || originalCommand, items);

    default:
      return findAction(targetText, items, direction);
  }
}

/**
 * ğŸ¤– AI ê¸°ë°˜ ìŒì„± ëª…ë ¹ ì²˜ë¦¬ (ì‹ ê·œ)
 * ì‚¬ìš©ì ìŒì„±ì„ AIë¡œ ë¶„ì„í•˜ì—¬ ì•¡ì…˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ í›„ ìˆœì°¨ ì‹¤í–‰
 * @param userInput ì‚¬ìš©ì ìŒì„± ì…ë ¥ í…ìŠ¤íŠ¸
 * @param items í˜„ì¬ í˜ì´ì§€ì˜ í¬ë¡¤ë§ëœ ìš”ì†Œë“¤
 * @returns Promise<VoiceCommandResult[]> ê° ë‹¨ê³„ë³„ ì‹¤í–‰ ê²°ê³¼
 */
export async function processAIVoiceCommand(
  userInput: string,
  items: CrawledItem[]
): Promise<VoiceCommandResult[]> {
  console.log(`ğŸ¤– [CONTROLLER] Processing AI voice command: "${userInput}"`);

  try {
    // 1. AIë¡œ ìŒì„± ëª…ë ¹ ë¶„ì„
    const aiController = getAIController();

    if (!aiController.isModelLoaded()) {
      console.warn('âš ï¸ [CONTROLLER] AI model not loaded, falling back to keyword-based processing');
      // AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
      return [processVoiceCommand({
        detectedAction: 'find',
        targetText: userInput,
        direction: null,
        originalCommand: userInput,
        items
      })];
    }

    const aiResult = await aiController.analyzeIntent(userInput);
    console.log(`ğŸ§  [CONTROLLER] AI analysis result:`, aiResult);

    // 2. AI ê²°ê³¼ë¥¼ voice-commands ì•¡ì…˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
    const actionSequence = mapAIToVoiceActions(aiResult, userInput);
    console.log(`ğŸ¯ [CONTROLLER] Generated action sequence:`, actionSequence);

    // 3. ì•¡ì…˜ ì‹œí€€ìŠ¤ ìˆœì°¨ ì‹¤í–‰
    const results: VoiceCommandResult[] = [];

    for (const [index, step] of actionSequence.steps.entries()) {
      console.log(`ğŸ”„ [CONTROLLER] Executing step ${index + 1}/${actionSequence.steps.length}:`, step);

      try {
        const result = await executeVoiceActionStep(step, items);
        results.push(result);

        // ë‹¨ê³„ë³„ ëŒ€ê¸° ì‹œê°„
        if (step.waitFor && step.waitFor > 0) {
          console.log(`â³ [CONTROLLER] Waiting ${step.waitFor}ms after step ${index + 1}`);
          await new Promise(resolve => setTimeout(resolve, step.waitFor));
        }

        // ì‹¤íŒ¨í•œ ê²½ìš° ì‹œí€€ìŠ¤ ì¤‘ë‹¨ ì—¬ë¶€ ê²°ì •
        if (result.type === "not_found" && step.priority === "high") {
          console.warn(`âš ï¸ [CONTROLLER] High priority step failed, stopping sequence:`, result);
          break;
        }
      } catch (stepError) {
        console.error(`âŒ [CONTROLLER] Step ${index + 1} execution failed:`, stepError);
        results.push({
          type: "not_found",
          message: `Step ${index + 1} failed: ${stepError instanceof Error ? stepError.message : 'Unknown error'}`
        });

        // ì¤‘ìš”í•œ ë‹¨ê³„ ì‹¤íŒ¨ ì‹œ ì‹œí€€ìŠ¤ ì¤‘ë‹¨
        if (step.priority === "high") {
          break;
        }
      }
    }

    console.log(`âœ… [CONTROLLER] AI voice command completed. Executed ${results.length} steps`);
    return results;

  } catch (aiError) {
    console.error('âŒ [CONTROLLER] AI voice command processing failed:', aiError);

    // AI ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
    console.log('ğŸ”„ [CONTROLLER] Falling back to keyword-based processing');
    return [processVoiceCommand({
      detectedAction: 'find',
      targetText: userInput,
      direction: null,
      originalCommand: userInput,
      items
    })];
  }
}

/**
 * ê°œë³„ ì•¡ì…˜ ìŠ¤í… ì‹¤í–‰
 */
async function executeVoiceActionStep(
  step: VoiceActionStep,
  items: CrawledItem[]
): Promise<VoiceCommandResult> {

  const payload: CommandPayload = {
    detectedAction: step.action.replace('_action', ''), // find_action â†’ find
    targetText: step.target || '',
    direction: null,
    originalCommand: step.value || step.target || '',
    items
  };

  // input_actionì˜ ê²½ìš° valueë¥¼ originalCommandë¡œ ì‚¬ìš©
  if (step.action === 'input_action' && step.value) {
    payload.originalCommand = step.value;
  }

  return processVoiceCommand(payload);
}
