// AI ê´€ë ¨ ë©”ì‹œì§€ ì²˜ë¦¬ í•¸ë“¤ëŸ¬ (Offscreen ì¤‘ê³„) - ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›

import { AIMessageRequest } from '../types/background-types';
import { offscreenManager } from '../controllers/managers/offscreen-manager';
import { getAIController } from '../../features/ai-inference/controllers/ai-controller';
import { AVAILABLE_MODELS } from '../../features/ai-inference/config/model-registry';

// ìš”ì²­ IDìš© ì¹´ìš´í„° (íƒ€ì„ìŠ¤íƒ¬í”„ì™€ ê²°í•©í•˜ì—¬ ê³ ìœ ì„± ë³´ì¥)
let requestCounter = 0;

/**
 * AI ê´€ë ¨ ë©”ì‹œì§€ë¥¼ Offscreenìœ¼ë¡œ ì¤‘ê³„í•˜ëŠ” í•¸ë“¤ëŸ¬
 * ê¸°ì¡´ background-old.tsì˜ ê²€ì¦ëœ ë¹„ë™ê¸° ì²˜ë¦¬ ë°©ì‹ ì ìš©
 */
export async function handleAIMessage(
  request: AIMessageRequest
): Promise<any> {
  // ì¤‘ë³µ ë””ë²„ê¹…: ìš”ì²­ ì „ì²´ ë¡œê·¸
  console.log(`ğŸ”„ [ai-handler] Processing AI request: ${request.action}`);
  console.log(`ğŸ” [ai-handler] Full request:`, request);
  console.log(`ğŸ“ [ai-handler] Request source: ${request.source || 'unknown'}, timestamp: ${request.timestamp || 'none'}`);
  
  try {
    // 1. Offscreen Document ì¤€ë¹„
    if (!offscreenManager.isReady()) {
      await offscreenManager.ensureReady();
      
      // Offscreen ì¤€ë¹„ ì™„ë£Œ ëŒ€ê¸°
      await new Promise<void>(resolve => {
        const listener = (msg: any) => {
          if (msg.action === 'offscreenReady') {
            chrome.runtime.onMessage.removeListener(listener);
            resolve();
          }
        };
        chrome.runtime.onMessage.addListener(listener);
      });
    }

    // 2. Offscreen ì¤€ë¹„ ìƒíƒœ í™•ì¸ ë° ëŒ€ê¸° (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)
    await offscreenManager.ensureReady();
    
    // 3. ì•¡ì…˜ëª… ë³€í™˜ (Background â†’ Offscreen)  
    const forwardAction = mapBackgroundActionToOffscreen(request.action);
    
    // 4. íƒ€ì„ìŠ¤íƒ¬í”„ + ì¹´ìš´í„° ê¸°ë°˜ ìš”ì²­ ID ìƒì„±
    const requestId = `${Date.now()}_${++requestCounter}`;
    
    // 5. Offscreenìœ¼ë¡œ ë©”ì‹œì§€ ì „ë‹¬ (ID í¬í•¨)
    const messageToSend = { 
      action: forwardAction, 
      requestId: requestId,
      token: request.token,
      command: request.command,
      failedTests: request.failedTests,
      snapshotId: request.snapshotId,
      description: request.description
    };
    // ì¤‘ë³µ ë””ë²„ê¹…: ì „ì†¡ ë©”ì‹œì§€ ë¡œê·¸
    console.log(`ğŸ“¤ [ai-handler] Sending to Offscreen:`, messageToSend);
    chrome.runtime.sendMessage(messageToSend);
    
    // 6. ì‘ë‹µ ëŒ€ê¸° (ID ê¸°ë°˜ ë§¤ì¹­ + íƒ€ì„ì•„ì›ƒ ì·¨ì†Œ)
    const expectedResponse = mapBackgroundActionToResponse(request.action);
    
    const response = await new Promise((resolve) => {
      let timeoutId: NodeJS.Timeout;
      
      const listener = (msg: any) => {
        // IDê°€ ì¼ì¹˜í•˜ëŠ” ì‘ë‹µë§Œ ì²˜ë¦¬
        if (msg.action === expectedResponse && msg.requestId === requestId) {
          chrome.runtime.onMessage.removeListener(listener);
          clearTimeout(timeoutId); // íƒ€ì„ì•„ì›ƒ ì·¨ì†Œ
          resolve(msg);
        }
      };
      chrome.runtime.onMessage.addListener(listener);
      
      // ë‹¤ìš´ë¡œë“œëŠ” 12ë¶„, ê¸°íƒ€ ì‘ì—…ì€ 30ì´ˆ íƒ€ì„ì•„ì›ƒ
      const timeoutDuration = request.action === 'downloadAIModel' ? 12 * 60 * 1000 : 30000;
      timeoutId = setTimeout(() => {
        chrome.runtime.onMessage.removeListener(listener);
        resolve({ error: 'AI operation timeout' });
      }, timeoutDuration);
    });
    
    return response;
    
  } catch (error: any) {
    return { error: error.message };
  }
}

/**
 * Background ì•¡ì…˜ëª…ì„ Offscreen ì•¡ì…˜ëª…ìœ¼ë¡œ ë³€í™˜ (ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›)
 */
function mapBackgroundActionToOffscreen(action: string): string {
  const actionMap: Record<string, string> = {
    'downloadAIModel': 'downloadModel',
    'initializeAI': 'initializeAI',
    'loadAIModel': 'initializeAI', // Load Modelë„ ê°™ì€ Offscreen ì•¡ì…˜ ì‚¬ìš©
    'getAIModelStatus': 'getModelStatus',
    'testAIAnalysis': 'analyzeIntent',
    'deleteAIModel': 'deleteModel',
    'learnFromFailedTests': 'learnFromFailedTests', // ìƒˆë¡œìš´ í•™ìŠµ ê¸°ëŠ¥
    'getLearnedStats': 'getLearnedStats', // í•™ìŠµ í˜„í™© ì¡°íšŒ
    'clearLearnedExamples': 'clearLearnedExamples', // í•™ìŠµ ë°ì´í„° ì´ˆê¸°í™”
    'createSnapshot': 'createSnapshot', // ìŠ¤ëƒ…ìƒ· ìƒì„±
    'getSnapshots': 'getSnapshots', // ìŠ¤ëƒ…ìƒ· ëª©ë¡
    'rollbackSnapshot': 'rollbackSnapshot', // ìŠ¤ëƒ…ìƒ· ë³µì›
    'deleteSnapshot': 'deleteSnapshot', // ìŠ¤ëƒ…ìƒ· ì‚­ì œ
    // ë‹¤ì¤‘ ëª¨ë¸ ì§€ì› ìƒˆ ì•¡ì…˜ë“¤
    'switchAIModel': 'switchModel',
    'getAvailableModels': 'getAvailableModels',
    'getAllModelsStatus': 'getAllModelsStatus',
    'getDownloadProgress': 'getDownloadProgress'
  };

  return actionMap[action] || action;
}

/**
 * Background ì•¡ì…˜ëª…ì„ ê¸°ëŒ€í•˜ëŠ” ì‘ë‹µ ì•¡ì…˜ëª…ìœ¼ë¡œ ë³€í™˜ (ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›)
 */
function mapBackgroundActionToResponse(action: string): string {
  const responseMap: Record<string, string> = {
    'downloadAIModel': 'modelLoaded',
    'deleteAIModel': 'modelDeleted',
    'initializeAI': 'aiInitialized',
    'loadAIModel': 'aiInitialized', // Load Modelë„ ê°™ì€ ì‘ë‹µ ê¸°ëŒ€
    'testAIAnalysis': 'analysisResult',
    'getAIModelStatus': 'modelStatusResponse',
    'learnFromFailedTests': 'learningCompleted', // í•™ìŠµ ì™„ë£Œ ì‘ë‹µ
    'getLearnedStats': 'statsResponse', // í•™ìŠµ í˜„í™© ì‘ë‹µ
    'clearLearnedExamples': 'clearCompleted', // ì´ˆê¸°í™” ì™„ë£Œ ì‘ë‹µ
    'createSnapshot': 'snapshotCreated', // ìŠ¤ëƒ…ìƒ· ìƒì„± ì™„ë£Œ
    'getSnapshots': 'snapshotsResponse', // ìŠ¤ëƒ…ìƒ· ëª©ë¡ ì‘ë‹µ
    'rollbackSnapshot': 'rollbackCompleted', // ë¡¤ë°± ì™„ë£Œ ì‘ë‹µ
    'deleteSnapshot': 'snapshotDeleted', // ìŠ¤ëƒ…ìƒ· ì‚­ì œ ì™„ë£¼
    // ë‹¤ì¤‘ ëª¨ë¸ ì§€ì› ìƒˆ ì‘ë‹µë“¤
    'switchAIModel': 'modelSwitched',
    'getAvailableModels': 'availableModelsResponse',
    'getAllModelsStatus': 'allModelsStatusResponse',
    'getDownloadProgress': 'downloadProgressResponse'
  };

  return responseMap[action] || 'modelStatusResponse';
}

// =============================================================================
// ğŸŒ ë‹¤ì¤‘ ëª¨ë¸ ì§€ì› í•¸ë“¤ëŸ¬ë“¤
// =============================================================================

/**
 * ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë° í˜„ì¬ ëª¨ë¸ ë°˜í™˜
 */
export async function handleGetAvailableModels(): Promise<any> {
  try {
    const aiController = getAIController();
    return {
      success: true,
      models: aiController.getAvailableModels(),
      currentModelId: aiController.getCurrentModelId()
    };
  } catch (error: any) {
    console.error('âŒ [ai-handler] Failed to get available models:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * ëª¨ë“  ëª¨ë¸ì˜ ìƒíƒœ ì¡°íšŒ
 */
export async function handleGetAllModelsStatus(): Promise<any> {
  try {
    const aiController = getAIController();
    const states = await aiController.getAllModelsStatus();
    return {
      success: true,
      states
    };
  } catch (error: any) {
    console.error('âŒ [ai-handler] Failed to get all models status:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * ë‹¤ìš´ë¡œë“œ ì§„í–‰ë¥  ì¡°íšŒ
 */
export async function handleGetDownloadProgress(): Promise<any> {
  try {
    const aiController = getAIController();
    const progress = aiController.getDownloadProgress();
    return {
      success: true,
      progress
    };
  } catch (error: any) {
    console.error('âŒ [ai-handler] Failed to get download progress:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * ëª¨ë¸ ì „í™˜ ì²˜ë¦¬
 */
export async function handleSwitchModel(modelId: string, token?: string): Promise<any> {
  try {
    console.log(`ğŸ”„ [ai-handler] Switching to model: ${modelId}`);
    const aiController = getAIController();
    const success = await aiController.switchModel(modelId, token);

    if (success) {
      // UIì— ëª¨ë¸ ì „í™˜ ì•Œë¦¼ ì „ì†¡
      try {
        chrome.runtime.sendMessage({
          action: 'modelSwitched',
          modelId: modelId,
          modelName: AVAILABLE_MODELS[modelId]?.name || modelId
        }).catch(() => {
          // ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨ëŠ” ì¡°ìš©íˆ ë¬´ì‹œ
        });
      } catch (error) {
        console.warn('âš ï¸ [ai-handler] Failed to notify model switch:', error);
      }

      return {
        success: true,
        modelId,
        message: 'Model switched successfully'
      };
    } else {
      return {
        success: false,
        error: 'Model switch failed'
      };
    }
  } catch (error: any) {
    console.error(`âŒ [ai-handler] Failed to switch to model ${modelId}:`, error);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * ë‹¤ì¤‘ ëª¨ë¸ ì§€ì› ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬
 */
export async function handleMultiModelDownload(modelId?: string, token?: string): Promise<any> {
  try {
    console.log(`ğŸ“¥ [ai-handler] Starting download for model: ${modelId || 'default'}`);

    // modelIdê°€ ì§€ì •ëœ ê²½ìš°, í•´ë‹¹ ëª¨ë¸ìš© ì»¸íŠ¸ë¡¤ëŸ¬ ìƒì„±
    const aiController = modelId ? getAIController(modelId) : getAIController();

    let success: boolean;
    if (modelId && aiController.getCurrentModelId() !== modelId) {
      // ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì „í™˜ í›„ ë‹¤ìš´ë¡œë“œ
      success = await aiController.switchModel(modelId, token);
    } else {
      // í˜„ì¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
      success = await aiController.downloadAndCacheModel(token || '', modelId);
    }

    return {
      success,
      modelId: aiController.getCurrentModelId(),
      message: success ? 'Download started successfully' : 'Download failed to start'
    };
  } catch (error: any) {
    console.error(`âŒ [ai-handler] Failed to start download for model ${modelId}:`, error);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * ë‹¤ì¤‘ ëª¨ë¸ ì§€ì› ì‚­ì œ ì²˜ë¦¬
 */
export async function handleMultiModelDelete(modelId?: string): Promise<any> {
  try {
    console.log(`ğŸ—‘ï¸ [ai-handler] Deleting model: ${modelId || 'current'}`);

    const aiController = getAIController();
    await aiController.deleteCachedModel(modelId);

    return {
      success: true,
      modelId: modelId || aiController.getCurrentModelId(),
      message: 'Model deleted successfully'
    };
  } catch (error: any) {
    console.error(`âŒ [ai-handler] Failed to delete model ${modelId}:`, error);
    return {
      success: false,
      error: error.message
    };
  }
}